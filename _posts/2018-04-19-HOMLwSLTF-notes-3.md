---
title:  "HOMLwSLaTF第三章阅读笔记"
excerpt: "第三章 Classification"
toc: true
toc_label: "目录"
toc_icon: "gear"
categories:
  - Machine_Learning
tags:
  - 机器学习
  - 分类
---

## MNIST

MNIST是一个著名的数据集, 本节对其进行了基本介绍. 使用numpy的random.permutation()随机打乱训练集.

## 训练二元分类器

本例中训练一个区分"5"和"非5"两种分类的分类器. 可以使用sklearn实现的SGD分类器, SGDClassifier, 它适于处理大数据集和进行在线学习.

## 评价表现

交叉检验. 可以通过借助sklearn自行实现交叉检验, 书中例子实现了一个基于分层抽样的K折交叉检验. 从书中的例子可以发现, 当正负例个数相差较大, 即使是完全不合理的模型也可能有很高的准确度. 因此要引入其他评价方法.

混淆矩阵. 行为实际类, 列为预测类, 元素为相应的数据项个数, 可通过混淆矩阵便捷地查看每对实际类和预测类的交集有多大. sklearn的confusion_matrix()是它的一个实现.

准确率(P)和召回率(R). sklearn的precision_score()和recall_score()可计算它们. 计算F1值(准确率和召回率的调和平均)的对应方法为f1_score().

准确率, 召回率间的折中. 划分正/负例的阈值设为PR平衡点较好. 注意sklearn不支持直接设定阈值. precision_recall_curve()可作PR曲线, 再调用matplotlib画出即可.

ROC曲线. 真正率, 假正率之间的曲线. sklearn的roc_curve()对其进行了实现; roc_auc_curve()可计算曲线下围成的面积. y=x代表纯随机分类,曲线离它越远说明分类效果越好. 正例罕见或者假正例比假负例重要时, 使用PR曲线进行评估较好, 否则使用ROC曲线较好.

## 多元分类

可划分类别有多种. 普通二元分类器要通过一定处理才可处理多分类问题, 在本例中,可以为每一种分类建立一个是/非二元分类器, 最后选择决策分数最高的分类器的分类结果(OvA). 也可以为每两对分类都建立一个二元分类器(OvO). 除SVM外一般采用OvA较好, sklearn对于在多分类问题中调用二元分类器时的默认选择也是它. 可以通过OneVsOneClassifier/OneVsRestClassifier手动规定.

使用StandardScaler()对数据进行缩放可降低误差.

## 误差分析

这里假设已经确定了模型种类, 要对其进行调整.

使用matplotlib的matshow()可以直观地查看混淆矩阵数据的分布状况. 较理想的图像是对角线明亮, 其他部分黑暗. 另外, 对混淆矩阵进行正则化(除以行和)可以发现哪几类的混淆几率较高, 未被正确分类为正例的行与被错误分类为正例的列对应的元素在图像上会较为明亮. 本例中, 发现3和5经常被混淆, 于是可以对数据进行处理, 强调它们差距较明显的特征.

## 多标签分类

同一个数据项可对应多个分类.  并非所有分类器都能实现多标签分类, KNN是一个可实现的例子. 若认为各标签并非同等重要, 可为它们设置权重.

## 多输出分类

是一般化的多标签分类. 每个标签可以是一个多维向量.  例:接受一个有噪音的图片, 输出一个干净的图片.

## 课后练习

1. 见第二章练习的第1题, 把参数设为KNeighborsClassifier的相应参数即可.
2. 先把原图像reshape(), 调用shift(), 再reshape()回去. 可参考numpy.reshape的文档.